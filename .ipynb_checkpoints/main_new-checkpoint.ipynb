{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "820f6754-de85-4da1-a8c8-75d85d64d971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this notebook with batik-pytorch kernel\n",
    "# Created by : Tri334 (github)\n",
    "# Modified by : hanatiara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf2536ba-6ae0-4895-84ec-ab68810cb550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import shutil as st\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "from torch.utils.data import WeightedRandomSampler, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "909417fc-74b2-4a40-8e45-4c90fde54612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a6dc5a4-1ec5-41f7-8b01-5ce008611bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79426399-ce07-4ef1-bede-447cd0db66e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = ['original', 'balance_patch', 'non_balance_patch','grayscale']\n",
    "sub_fold = ['train', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f723f36e-5dad-4f38-ad8f-b071d4582354",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'cleaned-dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eac3c678-a8b6-46e9-87d6-6ac2cebceb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder(used_data, fold, folder=folder):\n",
    "    fold = str(fold)\n",
    "    used_data = 'clean'\n",
    "    train = {\n",
    "        'original': used_data +'/fold '+ fold + '/'+ folder[0] +'/train',\n",
    "        'balance_patch': used_data +'/fold '+ fold+ '/'+ folder[1] +'/train',\n",
    "        'non_balance_patch': used_data +'/fold '+ fold+ '/'+ folder[2] +'/train',\n",
    "        'grayscale': used_data +'/fold '+ fold+ '/'+ folder[3] +'/train'\n",
    "    }\n",
    "    test = {\n",
    "        'original': used_data +'/fold '+ fold+ '/'+ folder[0] +'/test',\n",
    "        'balance_patch': used_data +'/fold '+ fold+ '/'+ folder[1] +'/test',\n",
    "        'non_balance_patch': used_data +'/fold '+ fold+ '/'+ folder[2] +'/test',\n",
    "        'grayscale': used_data +'/fold '+ fold+ '/'+ folder[3] +'/test'\n",
    "    }\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "511647a6-86c2-48fc-8a9e-c691927d5144",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naming_model(used_data,fold):\n",
    "    path = used_data +'/'+'fold '+str(fold)\n",
    "    if not os.path.isdir(path+'/model'):\n",
    "        os.makedirs(path+'/model')\n",
    "    if len(os.listdir(path+'/model')) == 0:\n",
    "        counter = 1\n",
    "    else:\n",
    "        counter = len(os.listdir(path+'/model')) + 1\n",
    "\n",
    "    path_save = path+'/model/'+str(counter) + '.pth'\n",
    "    return path_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07206ca3-5464-43e8-86c9-6a78e6da8d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getKelas(path):\n",
    "    kelas = os.listdir('cleaned-dataset/')\n",
    "    return kelas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4033bde1-fbb8-4f85-9c47-27e2e5fb03db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat folder\n",
    "def make_folder(path, folder, kelas, fold, sub_fold=sub_fold):\n",
    "    fold = str(fold+1)\n",
    "    for sub in sub_fold:\n",
    "        for item in kelas:\n",
    "            if not os.path.isdir(path + '/' + 'fold '+ fold + '/' + folder + '/' + sub + '/' + item):\n",
    "                os.makedirs(path + '/' + 'fold '+ fold + '/' + folder + '/' + sub + '/' + item)\n",
    "            else:\n",
    "                st.rmtree(path + '/' + 'fold '+ fold + '/' + folder + '/' + sub + '/' + item)\n",
    "                os.makedirs(path + '/' + 'fold '+ fold + '/' + folder + '/' + sub + '/' + item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78fb23bf-548e-4696-a890-3cbdecbb4a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat 5 fold ambil rate 20% val\n",
    "def make_fold(used_data,kelas, folder=folder, fold=5):\n",
    "    dst_n = 'clean'\n",
    "    src_n = 'cleaned-dataset'\n",
    "\n",
    "    folder=folder[0]\n",
    "\n",
    "    dataset = datasets.ImageFolder(src_n)\n",
    "    #Jumlah data tiap kelas\n",
    "    sum_label = [0, 0, 0, 0, 0]\n",
    "    for gambar, label in dataset.imgs:\n",
    "        sum_label[label] += 1\n",
    "\n",
    "    #Jumlah item yang dibutuhkan tiap kelas\n",
    "    needed = [math.floor(i * 0.2) for i in sum_label]\n",
    "    needed = {i: needed[i] for i in range(len(needed))}\n",
    "\n",
    "    #Mendapatkan idx dari tiap kelas secara acak sesuai jumlah item yang dibutuhkan\n",
    "    taken = [[], [], [], [], []]\n",
    "    for fld in range(fold):\n",
    "        # Membuat folder dan menghapus folder lama\n",
    "        make_folder(dst_n, folder, kelas,fld)\n",
    "        for kls in needed:\n",
    "            cek = os.listdir(src_n + '/' + dataset.classes[kls])\n",
    "            must_taken = [i for i in range(len(cek))]\n",
    "            random.shuffle(must_taken)\n",
    "            temp = []\n",
    "            counter = 0\n",
    "            #Perulangan sebanyak item yang dibutuhkan per kelas\n",
    "            while len(temp) < needed[kls]:\n",
    "                if must_taken[counter] not in taken[kls]:\n",
    "                    # print('ok')\n",
    "                    temp.append(must_taken[counter])\n",
    "                    taken[kls].append(must_taken[counter])\n",
    "                counter += 1\n",
    "\n",
    "            # Memindahkan file\n",
    "            for i in range(len(cek)):\n",
    "                if i in temp:\n",
    "                    test = 'test'\n",
    "                else:\n",
    "                    test = 'train'\n",
    "                src = src_n + '/' + dataset.classes[kls] + '/' + cek[i]\n",
    "                desti = dst_n + '/' + 'fold ' \\\n",
    "                        + str(fld + 1) + '/' + folder + '/' \\\n",
    "                        + test + '/' + dataset.classes[kls] \\\n",
    "                        + '/' + cek[i]\n",
    "                st.copyfile(src, desti)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5f6d7c4-9d28-4a09-8c19-7b42b70fa7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat balance patch\n",
    "def patch_balance(used_data,kelas,folder=folder,expected_balance=1500,fold=5):\n",
    "    folder_dst = folder[1]\n",
    "    folder_src = folder[0]\n",
    "\n",
    "    used_data = 'clean'\n",
    "\n",
    "    for jumlah_fold in range(fold):\n",
    "        path = used_data + '/' + 'fold ' + str(jumlah_fold + 1) + '/' + folder_src + '/' + 'train'\n",
    "        print(path)\n",
    "        sum_label = [0, 0, 0, 0, 0]\n",
    "\n",
    "        for gambar, label in datasets.ImageFolder(path).imgs:\n",
    "            sum_label[label] += 1\n",
    "\n",
    "        expected_balanced = expected_balance / len(kelas)\n",
    "        # print(expected_balance)\n",
    "        # print(needed)\n",
    "        needed = []\n",
    "        for item in sum_label:\n",
    "            temp = 0\n",
    "            temp2 = 0\n",
    "            while temp2 < expected_balanced:\n",
    "                item -= 1\n",
    "                temp += 1\n",
    "                temp2 = temp * 4 + item\n",
    "            needed.append(temp)\n",
    "        slice2 = {kelas[i]: needed[i] for i in range(len(kelas))}\n",
    "        # Check if possible\n",
    "        # print(slice2)\n",
    "        # print(needed)\n",
    "\n",
    "        check = [sum_label[i] - needed[i] for i in range(len(kelas))]\n",
    "        # checking\n",
    "        sub_fold = ['train', 'test']\n",
    "\n",
    "        possible = True\n",
    "        for item in check:\n",
    "            if item < 0:\n",
    "                possible = False\n",
    "                print(check)\n",
    "\n",
    "        if possible:\n",
    "            print('Requirement is met âœ”')\n",
    "            print('Getting Ready...\\n')\n",
    "            make_folder(used_data, folder_dst, kelas, jumlah_fold)\n",
    "\n",
    "            num_slices_per_axis = 2\n",
    "            # print(path)\n",
    "\n",
    "            source_slice = {}\n",
    "            source_original = {}\n",
    "            for train in sub_fold:\n",
    "                # print(train)\n",
    "                iter = 0\n",
    "                if train == 'train':\n",
    "                    pathx = used_data + '/' + 'fold '+str(jumlah_fold+1) + '/' + 'original' + '/' + train + '/'\n",
    "                    # print(pathx)\n",
    "                    for kls in kelas:\n",
    "                        # print(kls)\n",
    "                        img = os.listdir(pathx + kls)\n",
    "                        original_temp = [x for x in img]\n",
    "                        slice_temp = []\n",
    "                        for i in range(slice2[kls]):\n",
    "                            try:\n",
    "                                ran = random.randint(0, len(original_temp) - 1)\n",
    "                                test2 = original_temp[ran]\n",
    "                                if test2 not in slice_temp:\n",
    "                                    # print(test2)\n",
    "                                    slice_temp.append(original_temp.pop(ran))\n",
    "                                    # counter += 1\n",
    "                            except:\n",
    "                                print('')\n",
    "                                # print(len(original_temp))\n",
    "                        source_slice[kls] = slice_temp\n",
    "                        source_original[kls] = original_temp\n",
    "                    tesx = {'slice': source_slice,'original': source_original}\n",
    "\n",
    "                    #Memindahkan data\n",
    "                    for orislice in tesx:\n",
    "                        for kls in kelas:\n",
    "                            if orislice == 'slice':\n",
    "                                for item in source_slice[kls]:\n",
    "                                    img = cv2.imread(pathx + kls + '/' + item)\n",
    "                                    try:\n",
    "                                        slice_shape = (int(img.shape[0] / num_slices_per_axis), int(img.shape[1] / num_slices_per_axis))\n",
    "                                        for i in range(num_slices_per_axis):\n",
    "                                            for j in range(num_slices_per_axis):\n",
    "                                                top_left = (int(i * slice_shape[0]), int(j * slice_shape[1]))\n",
    "                                                crop = img[top_left[0]:(top_left[0] + slice_shape[0]),\n",
    "                                                       top_left[1]:(top_left[1] + slice_shape[1])]\n",
    "                                                # Menaruh hasil pembelahan image\n",
    "                                                dst = used_data + '/' + 'fold '+str(jumlah_fold+1) + '/' + folder_dst + '/' + train + '/' \\\n",
    "                                                      + kls + '/' + (str(iter)) + '_' + kls + '.jpg'\n",
    "                                                # print(dst)\n",
    "                                                # print(dst)\n",
    "                                                cv2.imwrite(dst, crop)\n",
    "                                                iter+=1\n",
    "                                    except: print(img)\n",
    "                            elif orislice == 'original':\n",
    "                                for item in source_original[kls]:\n",
    "                                    src = used_data + '/' + 'fold '+str(jumlah_fold+1) + '/' + folder_src + '/' + train + '/' + kls + '/' + item\n",
    "                                    desti = used_data + '/' + 'fold '+str(jumlah_fold+1) + '/' + folder_dst + '/' + train + '/' + kls + '/' + item\n",
    "                                    try:\n",
    "                                        # print(src)\n",
    "                                        # print('')\n",
    "                                        st.copyfile(src, desti)\n",
    "                                    except:\n",
    "                                        # print(src)\n",
    "                                        print('')\n",
    "                        # print('Done ')\n",
    "                else:\n",
    "                    # print(fold)\n",
    "                    dat = datasets.ImageFolder(used_data + '/' + 'fold '+str(jumlah_fold+1) + '/' + folder_src+'/'+train)\n",
    "                    for image in dat.imgs:\n",
    "                        # print(dat.classes[image[1]])\n",
    "                        img = cv2.imread(image[0])\n",
    "                        try:\n",
    "                            slice_shape = (int(img.shape[0] / num_slices_per_axis), int(img.shape[1] / num_slices_per_axis))\n",
    "                            for i in range(num_slices_per_axis):\n",
    "                                for j in range(num_slices_per_axis):\n",
    "                                    top_left = (int(i * slice_shape[0]), int(j * slice_shape[1]))\n",
    "                                    crop = img[top_left[0]:(top_left[0] + slice_shape[0]),\n",
    "                                           top_left[1]:(top_left[1] + slice_shape[1])]\n",
    "                                    # Menaruh hasil pembelahan image\n",
    "                                    cv2.imwrite(\n",
    "                                        used_data +'/'+ 'fold '+str(jumlah_fold+1) + '/' + folder_dst + '/'\n",
    "                                        + train + '/' + str(dat.classes[image[1]]) + '/' + str(iter) + '_' +\n",
    "                                        str((dat.classes[image[1]]) + '.jpg'), crop)\n",
    "                                    iter += 1\n",
    "                                    # print(iter)\n",
    "                        except:\n",
    "                            # print(img)\n",
    "                            print('')\n",
    "        else: print('## Try lowering expected total sliced data ##\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9634e102-aadb-4e31-afee-14275466f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat non balance patch\n",
    "def patch_non_balance(used_data,kelas,folder=folder, sub_fold=sub_fold,fold=5):\n",
    "    # Penyalinan image sliced ke folder baru\n",
    "    folder_dst = folder[2]\n",
    "    folder_src = folder[0]\n",
    "\n",
    "    used_data = 'clean'\n",
    "\n",
    "    for jumlah_fold in range(fold):\n",
    "\n",
    "        path = used_data + '/' + 'fold ' + str(jumlah_fold + 1) + '/' + folder_src + '/'\n",
    "\n",
    "        make_folder(used_data, folder_dst, kelas, jumlah_fold)\n",
    "        num_slices_per_axis = 2\n",
    "        iter = 0\n",
    "\n",
    "        for train in sub_fold:\n",
    "            dat = datasets.ImageFolder(path + '/' + train)\n",
    "            print(dat)\n",
    "            for image in dat.imgs:\n",
    "                # print(dat.classes[image[1]])\n",
    "                img = cv2.imread(image[0])\n",
    "                try:\n",
    "                    slice_shape = (int(img.shape[0] / num_slices_per_axis), int(img.shape[1] / num_slices_per_axis))\n",
    "                    for i in range(num_slices_per_axis):\n",
    "                        for j in range(num_slices_per_axis):\n",
    "                            top_left = (int(i * slice_shape[0]), int(j * slice_shape[1]))\n",
    "                            crop = img[top_left[0]:(top_left[0] + slice_shape[0]),top_left[1]:(top_left[1] + slice_shape[1])]\n",
    "                            # Menaruh hasil pembelahan image\n",
    "                            cv2.imwrite(\n",
    "                                used_data + '/' + 'fold ' + str(jumlah_fold + 1) + '/' + folder_dst + '/'\n",
    "                                + train + '/' + str(dat.classes[image[1]]) + '/' + str(iter) + '_' +\n",
    "                                str((dat.classes[image[1]]) + '.jpg'), crop)\n",
    "                            iter += 1\n",
    "                            # print(iter)\n",
    "                except:\n",
    "                    print(img)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "407e7957-982e-42e0-b7d5-a2c8bcf29216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loader data\n",
    "def data_load(batch_size, transform, train, val, sampler=False):\n",
    "    # About batch size\n",
    "    # https://discuss.pytorch.org/t/i-get-a-much-better-result-with-batch-size-1-than-when-i-use-a-higher-batch-size/20477/4\n",
    "    # print(train,val,test)\n",
    "\n",
    "    train_s = datasets.ImageFolder(train, transform=transform['train'])\n",
    "    val_s = datasets.ImageFolder(val, transform=transform['val'])\n",
    "    # test_s = datasets.ImageFolder(test, transform=transform['val'])\n",
    "\n",
    "    train_load_s = DataLoader(train_s, shuffle=True, batch_size=batch_size,pin_memory=True)\n",
    "    if sampler:\n",
    "        samplerx = Wightedrandomsampler(train_s)\n",
    "        train_load_s = DataLoader(train_s, sampler=samplerx['sampler'], batch_size=batch_size,pin_memory=True)\n",
    "    val_load_s = DataLoader(val_s, shuffle=False, batch_size=batch_size,pin_memory=True)\n",
    "    # test_load_s = DataLoader(test_s,shuffle=False, batch_size=batch_size,pin_memory=True)\n",
    "    image_folder = {\n",
    "        'train': train_s,\n",
    "        'val': val_s,\n",
    "        # 'test': test_s\n",
    "    }\n",
    "    loader_data = {\n",
    "        'train': train_load_s,\n",
    "        'val': val_load_s,\n",
    "        # 'test': test_load_s\n",
    "    }\n",
    "    dataset_sizes = {\n",
    "        'train': len(train_s),\n",
    "        'val': len(val_s),\n",
    "        # 'test': len(test_s)\n",
    "    }\n",
    "    load_data = {\n",
    "        'loader': loader_data,\n",
    "        'sizes': dataset_sizes,\n",
    "        'image': image_folder\n",
    "    }\n",
    "    return load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "072e691f-f7d7-4242-90bd-af1a76b847b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat image agar bisa di petakan\n",
    "def display(image):\n",
    "    img = image\n",
    "    img = img.numpy()\n",
    "    img = np.transpose(img, (1, 2, 0))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a86901b1-ca0b-48a1-bfbf-d93a3a97ab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat gambar hasil transfor bisa dilihat mata\n",
    "def display_image(dataset):\n",
    "    fig, axis = plt.subplots(3, 3, figsize=(15, 10))\n",
    "    for i, ax in enumerate(axis.flat):\n",
    "        with torch.no_grad():\n",
    "            ran = random.randint(1, len(dataset) - 1)\n",
    "            image, label = dataset[ran][0], dataset.classes[dataset[ran][1]]\n",
    "            title = label\n",
    "            ax.imshow(display(image))\n",
    "            ax.set(title=title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2af6150-d642-4637-bf02-28c0df21461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat sampler untuk membalancing data\n",
    "def Wightedrandomsampler(Dataset):\n",
    "    root = Dataset\n",
    "    sum_label = [0, 0, 0, 0, 0]\n",
    "    for gambar, label in root.imgs:\n",
    "        sum_label[label] += 1\n",
    "    weight = [1. / x for x in sum_label]\n",
    "    weight = torch.FloatTensor(weight)\n",
    "    samples_weight = [weight[t].to(device) for t in root.targets]\n",
    "    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
    "    sampler = {\n",
    "        'weight': samples_weight,\n",
    "        'sampler' : sampler\n",
    "    }\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a273afe5-f773-466d-a865-32cd6c44cede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "def config_model_mobile(dropout, lr, weight_decay, data_loader, kelas, pretrained=True, weight_entropy=False, freeze=False):\n",
    "    model = models.mobilenet_v2(pretrained=pretrained)\n",
    "\n",
    "    # Freeze model parameters if specified\n",
    "    if freeze:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Modify the last layer to match the number of classes\n",
    "    feature = model.classifier[1].in_features\n",
    "    model.classifier[1] = nn.Linear(feature, len(kelas))\n",
    "    \n",
    "    # Add dropout if specified\n",
    "    if dropout:\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(feature, len(kelas))\n",
    "        )\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Configure criterion and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if weight_entropy:\n",
    "        samplerx = Wightedrandomsampler(data_loader['image']['train'])\n",
    "        criterion = nn.CrossEntropyLoss(weight=samplerx['weight'])\n",
    "\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    if weight_decay:\n",
    "        optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    expLr_scheduler = lr_scheduler.StepLR(optim, step_size=30, gamma=0.1)\n",
    "\n",
    "    # Pack configuration into a dictionary\n",
    "    config = {\n",
    "        'model': model,\n",
    "        'criterion': criterion,\n",
    "        'optim': optim,\n",
    "        'lr_scheduler': expLr_scheduler\n",
    "    }\n",
    "\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c1899092-54d6-48a4-9c25-e15c5282c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_model(dropout,lr,weight_decay,data_loader,kelas,pretrained=True,weight_entropy = False,freeze=False):\n",
    "    model = models.resnet18(pretrained=pretrained)\n",
    "    if freeze:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    feature = model.fc.in_features\n",
    "    model.fc = torch.nn.Linear(feature, len(kelas))\n",
    "    if dropout:\n",
    "        model.fc = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(dropout),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(feature,len(kelas))\n",
    "        )\n",
    "    model = model.to(device)\n",
    "\n",
    "    # config criterion, optim, lr\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    if weight_entropy:\n",
    "        samplerx = Wightedrandomsampler(data_loader['image']['train'])\n",
    "        criterion = torch.nn.CrossEntropyLoss(weight=samplerx['weight'])\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    if weight_decay:\n",
    "        optim = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    expLr_scheduler = lr_scheduler.StepLR(optim, step_size=30, gamma=0.1)\n",
    "\n",
    "    config={'model': model,\n",
    "            'criterion': criterion,\n",
    "            'optim': optim,\n",
    "            'lr_scheduler': expLr_scheduler}\n",
    "\n",
    "    return config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "152ace7f-a704-4176-8ed5-7a365336bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(data_loader,config,join=False):\n",
    "    counter = 0\n",
    "    counter2 = 0\n",
    "    add = [0]\n",
    "    all_classx = torch.tensor([]).to(device)\n",
    "    new_masukan = torch.tensor([]).to(device)\n",
    "    with torch.no_grad():\n",
    "        config['model'].eval()\n",
    "        for i, (masukan, all_class) in enumerate(data_loader['loader']['val']):\n",
    "            masukan = masukan.to(device)\n",
    "            keluaran = config['model'](masukan)\n",
    "            # config['optim'].zero_grad()\n",
    "            if join:\n",
    "                for item in all_class:\n",
    "                    counter += 1\n",
    "                    if counter == 4:\n",
    "                        x = item.view(1)\n",
    "                        all_classx= torch.cat((all_classx, x.to(device)),0)\n",
    "                        counter=0\n",
    "\n",
    "                for item in keluaran:\n",
    "                    if counter2 != 4:\n",
    "                        counter2 += 1\n",
    "                        add[0] += item\n",
    "                        add[0] = add[0].view(1,5)\n",
    "                        # print(item)\n",
    "                        if counter2 == 4:\n",
    "                            new_masukan = torch.cat((new_masukan,add[0]),0)\n",
    "                            # print('='*5)\n",
    "                            # print(add[0])\n",
    "                            # print('='*5)\n",
    "                            add[0]=0\n",
    "                            counter2=0\n",
    "            else:\n",
    "                new_masukan = torch.cat((new_masukan,keluaran),0)\n",
    "                all_classx = torch.cat((all_classx,all_class.to(device)),0)\n",
    "\n",
    "    eval ={\n",
    "        'prediksi':new_masukan,\n",
    "        'kelas' : all_classx\n",
    "    }\n",
    "    return eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1849c333-a27b-4861-a378-014e16a1a17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(all_class,keluaran,kelas):\n",
    "    confusion_matrix = torch.zeros(len(kelas), len(kelas))\n",
    "    correct_pred = {classname: 0 for classname in kelas}\n",
    "    total_pred = {classname: 0 for classname in kelas}\n",
    "    _, prediksi = torch.max(keluaran, 1)\n",
    "\n",
    "    for asli, pred in zip(all_class.view(-1), prediksi.view(-1)):\n",
    "        confusion_matrix[asli.int(), pred.int()] += 1\n",
    "\n",
    "    for label, predik in zip(all_class.int(), prediksi):\n",
    "        if label == predik:\n",
    "            correct_pred[kelas[label]] += 1\n",
    "        total_pred[kelas[label]] += 1\n",
    "\n",
    "    all_acc = []\n",
    "    for classname, correct_count in correct_pred.items():\n",
    "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "        all_acc.append(accuracy)\n",
    "    tot_acc = sum(all_acc) / len(kelas)\n",
    "    eval = {\n",
    "        'matrix': confusion_matrix,\n",
    "        'acc': tot_acc\n",
    "    }\n",
    "    return eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b41cbd69-a809-4cfb-a70a-96db61ee22d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coba_train(config, transform, data_loader, epoch,pretrained,sampler, dropout, batch_sizes,sliced,weight_entropy,weight_decay,path_save, device=device ,join=False):\n",
    "\n",
    "    waktu_mulai = time.time()\n",
    "    val_acc = []\n",
    "    loss_var = []\n",
    "    test_acc = []\n",
    "    model_terbaik = copy.deepcopy(config['model'].state_dict())\n",
    "    akurasi_terbaik = 0.0\n",
    "    loss_terbaik = 0.0\n",
    "\n",
    "    for poch in range(epoch):\n",
    "        print('Epoch {}/{}'.format(poch, epoch - 1))\n",
    "        print('Lr:', config['optim'].param_groups[0]['lr'])\n",
    "        print(10 * '=')\n",
    "\n",
    "        # fase ada dua yaitu train dan validasi\n",
    "        for fase in ['train', 'val']:\n",
    "            if fase == 'train':\n",
    "                # Fase training\n",
    "                config['model'].train()\n",
    "            else:\n",
    "                # Fase evaluasi\n",
    "                config['model'].eval()\n",
    "\n",
    "            loss_saatIni = 0.0\n",
    "            akurasi_saatIni = 0.0\n",
    "\n",
    "            # Iterasi data\n",
    "            for masukan, label in data_loader['loader'][fase]:\n",
    "                masukan = masukan.to(device)\n",
    "                label = label.to(device)\n",
    "\n",
    "                # optime zero params gradient untuk backpropagasi\n",
    "                config['optim'].zero_grad()\n",
    "\n",
    "                # Propagasi maju\n",
    "                with torch.set_grad_enabled(fase == 'train'):\n",
    "                    keluaran = config['model'](masukan)\n",
    "                    _, prediksi = torch.max(keluaran, 1)\n",
    "                    loss = config['criterion'](keluaran, label)\n",
    "\n",
    "                    # Propagasi balik + lr step\n",
    "                    if fase == 'train':\n",
    "                        loss.backward()\n",
    "                        config['optim'].step()\n",
    "\n",
    "                # Untuk statistik\n",
    "                loss_saatIni += loss.item() * masukan.size(0)\n",
    "                akurasi_saatIni += torch.sum(prediksi == label.data)\n",
    "\n",
    "            if fase == 'train':\n",
    "                config['lr_scheduler'].step()\n",
    "\n",
    "            epoch_loss = loss_saatIni / data_loader['sizes'][fase]\n",
    "            loss_var.append(epoch_loss)\n",
    "            epoch_acc = akurasi_saatIni / data_loader['sizes'][fase]\n",
    "            val_acc.append(epoch_acc)\n",
    "\n",
    "\n",
    "            print('{} Loss: {:.5f} Akurasi: {:.5f}'.format(\n",
    "                fase, epoch_loss, epoch_acc\n",
    "            ))\n",
    "\n",
    "            # Menyalin model\n",
    "            if fase == 'val' and epoch_acc > akurasi_terbaik:\n",
    "                akurasi_terbaik = epoch_acc\n",
    "                loss_terbaik = epoch_loss\n",
    "                model_terbaik = config['model'].state_dict()\n",
    "                optimx = config['optim'].state_dict()\n",
    "                print('Best Val Test Acc âœ”')\n",
    "\n",
    "        print()\n",
    "\n",
    "    waktu_selesai = time.time() - waktu_mulai\n",
    "    print('Training selesai pada {:.0f} menit {:.0f} detik'.format(\n",
    "        waktu_selesai // 60, waktu_selesai % 60\n",
    "    ))\n",
    "    print('Validasi Terbaik: {:3f}'.format(akurasi_terbaik))\n",
    "    print('Dengan Loss: {:3f}'.format(loss_terbaik))\n",
    "\n",
    "    # Menyimpan model, epoch, loss, dll\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'optim': optimx,\n",
    "        'model': model_terbaik,\n",
    "        'loss': loss_terbaik,\n",
    "        'acc': akurasi_terbaik,\n",
    "        'transform': transform,\n",
    "        'loss_plot': loss_var,\n",
    "        'acc_plot': val_acc,\n",
    "        'test_plot': test_acc,\n",
    "        'batch_sizes': batch_sizes,\n",
    "        'pretrain': pretrained,\n",
    "        'using_sampler': sampler,\n",
    "        'dropout': dropout,\n",
    "        'slice': sliced,\n",
    "        'weight_entropy': weight_entropy,\n",
    "        'decay': weight_decay,\n",
    "        'data_loader':data_loader,\n",
    "        'join': join,\n",
    "        'config': config}, path_save)\n",
    "\n",
    "\n",
    "    # model.load_state_dict(model_terbaik)\n",
    "    # return model,loss_var,val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2845c666-095d-47e1-9210-c554cca0a228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix(confusion_matrix,tot_acc,path,nama_plot,kelas):\n",
    "    # Membuat confusion matrix\n",
    "    if not os.path.isdir(path+'/plot_matrix'):\n",
    "        os.makedirs(path+'/plot_matrix')\n",
    "    pathx = path+'/plot_matrix/'\n",
    "    title = 'Confusion Matrix | rata-rata: {}% '.format(tot_acc)\n",
    "    plt.imshow(confusion_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(kelas))\n",
    "    plt.xticks(tick_marks, kelas, rotation=0)\n",
    "    plt.yticks(tick_marks, kelas, rotation=0)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    threshold = confusion_matrix.max() / 2.\n",
    "    for i, j in itertools.product(range(confusion_matrix.shape[0]), range(confusion_matrix.shape[1])):\n",
    "        plt.text(j, i, format(confusion_matrix[i, j], fmt), horizontalalignment=\"center\",\n",
    "                 color='white' if confusion_matrix[i, j] > threshold else \"black\")\n",
    "\n",
    "    plt.savefig(pathx + str(nama_plot) + '.png')\n",
    "    plt.clf()\n",
    "\n",
    "def plot_model(model_loss, model_acc,nama_plot,path):\n",
    "    if not os.path.isdir(path+'/plot_acc_loss'):\n",
    "        os.makedirs(path+'/plot_acc_loss')\n",
    "\n",
    "    path_plot = path+'/plot_acc_loss/'\n",
    "    train_loss = model_loss[::2]\n",
    "    val_loss = model_loss[1::2]\n",
    "\n",
    "    temp = []\n",
    "    for item in model_acc:\n",
    "        temp.append(item.item())\n",
    "\n",
    "    train_acc = temp[::2]\n",
    "    vals_acc = temp[1::2]\n",
    "\n",
    "    # Saatnya plot perbandingan\n",
    "\n",
    "    # plot perbandingan Loss\n",
    "    plt.title('Perbandingan Akurasi')\n",
    "    plt.plot(train_acc, label='Train Acc')\n",
    "    plt.plot(vals_acc, label='Val Acc')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Akurasi\")\n",
    "    plt.legend()\n",
    "    # plt.show()\n",
    "    plt.savefig(path_plot +'Akurasi_' +str(nama_plot) + '.png')\n",
    "    plt.clf()\n",
    "\n",
    "    plt.title('Perbandingan Loss')\n",
    "    plt.plot(train_loss, label='Train Loss')\n",
    "    plt.plot(val_loss, label='Val Loss')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.savefig(path_plot + 'Loss_' +str(nama_plot) + '.png')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ce8a75c-1964-4c7b-8b15-1c6886468215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model(path, num_mode):\n",
    "        path_mod = path + 'model/' + str(num_mode) + '.pth'\n",
    "        checkpoint = torch.load(path_mod)\n",
    "        try:\n",
    "            print('epoch: {} \\nAcc: {} \\nloss: {} \\ntransform: {} \\nbatch sizes: {} \\npretrain: {} \\nusing sampler: {} '\n",
    "                  '\\ndropout: {} \\nweight_decay: {} \\n Data: {}'.format(\n",
    "                checkpoint['epoch'],\n",
    "                checkpoint['acc'],\n",
    "                checkpoint['loss'],\n",
    "                checkpoint['transform'],\n",
    "                checkpoint['batch_sizes'],\n",
    "                checkpoint['pretrain'],\n",
    "                checkpoint['using_sampler'],\n",
    "                checkpoint['dropout'],\n",
    "                checkpoint['decay'],\n",
    "                checkpoint['slice'],\n",
    "            ))\n",
    "        except:\n",
    "            print('not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9836c79f-3055-4ccf-b21d-68e0e2d7cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Mencoba kode\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4680024d-1e4b-4403-9999-6c570fb99794",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'dataset_grayscale'\n",
    "select_fold = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2779b20-ae01-4aec-8dcd-cd7a57f1671d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e47a548c-c768-42e8-bbdf-a406e95af48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grayscale\n",
      "({'original': 'clean/fold 2/original/train', 'balance_patch': 'clean/fold 2/balance_patch/train', 'non_balance_patch': 'clean/fold 2/non_balance_patch/train', 'grayscale': 'clean/fold 2/grayscale/train'}, {'original': 'clean/fold 2/original/test', 'balance_patch': 'clean/fold 2/balance_patch/test', 'non_balance_patch': 'clean/fold 2/non_balance_patch/test', 'grayscale': 'clean/fold 2/grayscale/test'})\n"
     ]
    }
   ],
   "source": [
    "data = ['original','balance_patch','non_balance_patch','grayscale']\n",
    "\n",
    "selected_data = data[3]\n",
    "\n",
    "if selected_data == 'original':\n",
    "    join = False\n",
    "else:\n",
    "    join = True\n",
    "\n",
    "path_mod = 'clean/fold '+str(select_fold)+'/'\n",
    "path_save = naming_model('clean',select_fold)\n",
    "kelas = getKelas(path)\n",
    "data_folder = get_folder(path,select_fold)\n",
    "\n",
    "print(selected_data)\n",
    "print(data_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3fe7384-fb7b-42e0-916b-8c5ec4ba5bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['batik-bali', 'batik-betawi', 'batik-celup', 'batik-cendrawasih', 'batik-ceplok', 'batik-ciamis', 'batik-garutan', 'batik-gentongan', 'batik-kawung', 'batik-keraton', 'batik-lasem', 'batik-megamendung', 'batik-parang', 'batik-pekalongan', 'batik-priangan', 'batik-sekar', 'batik-sidoluhur', 'batik-sidomukti', 'batik-sogan', 'batik-tambal']\n",
      "clean/fold 2/model/3.pth\n"
     ]
    }
   ],
   "source": [
    "# Check Class List\n",
    "print(kelas)\n",
    "# Check model path\n",
    "print(path_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9de60d29-4cf6-42d8-be6d-41c44fb60e39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 'clean/fold 2/grayscale/train', 'test': 'clean/fold 2/grayscale/test'}\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'train': data_folder[0][selected_data],\n",
    "    'test': data_folder[1][selected_data],\n",
    "}\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ddc7753-9fa8-481b-ba46-35da7ccbb088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "grayscale_path = 'dataset_grayscale'\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def convert_dataset_to_grayscale(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for class_name in os.listdir(input_dir):\n",
    "        class_path = os.path.join(input_dir, class_name)\n",
    "        output_class_path = os.path.join(output_dir, class_name)\n",
    "        os.makedirs(output_class_path, exist_ok=True)\n",
    "        \n",
    "        for image_name in os.listdir(class_path):\n",
    "            image_path = os.path.join(class_path, image_name)\n",
    "            image = Image.open(image_path)\n",
    "            gray_image = image.convert('L')  # Convert to grayscale\n",
    "            gray_image.save(os.path.join(output_class_path, image_name))\n",
    "\n",
    "# Example usage\n",
    "convert_dataset_to_grayscale(path, grayscale_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f30e8259-0216-4eac-ba58-104b1b8802bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split into train and test folders successfully.\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into train and test\n",
    "\n",
    "def split_dataset(data_dir, output_dir, test_ratio=0.2, seed=42):\n",
    "    # Define paths for train and test datasets\n",
    "    train_dir = os.path.join(output_dir, 'train')\n",
    "    test_dir = os.path.join(output_dir, 'test')\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    # Set random seed for reproducibility\n",
    "    random.seed(seed)\n",
    "\n",
    "    # Loop through each class folder\n",
    "    for class_name in os.listdir(data_dir):\n",
    "        class_dir = os.path.join(data_dir, class_name)\n",
    "        \n",
    "        if os.path.isdir(class_dir):\n",
    "            # Create class directories in train and test folders\n",
    "            os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
    "            os.makedirs(os.path.join(test_dir, class_name), exist_ok=True)\n",
    "\n",
    "            # Get list of all images in the class folder\n",
    "            images = os.listdir(class_dir)\n",
    "            total_images = len(images)\n",
    "\n",
    "            # Calculate the number of test samples\n",
    "            test_count = int(total_images * test_ratio)\n",
    "\n",
    "            # Randomly select test images\n",
    "            test_images = random.sample(images, test_count)\n",
    "            train_images = [img for img in images if img not in test_images]\n",
    "\n",
    "            # Copy images to respective train and test directories\n",
    "            for img_name in train_images:\n",
    "                src_path = os.path.join(class_dir, img_name)\n",
    "                dst_path = os.path.join(train_dir, class_name, img_name)\n",
    "                st.copy2(src_path, dst_path)\n",
    "\n",
    "            for img_name in test_images:\n",
    "                src_path = os.path.join(class_dir, img_name)\n",
    "                dst_path = os.path.join(test_dir, class_name, img_name)\n",
    "                st.copy2(src_path, dst_path)\n",
    "\n",
    "    print(\"Dataset split into train and test folders successfully.\")\n",
    "\n",
    "data_dir = path  # Path to the original dataset\n",
    "output_dir = path_mod + selected_data\n",
    "\n",
    "split_dataset(data_dir, output_dir, test_ratio=0.2, seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "842b4b5a-d41f-4ecf-a537-f7e77fbc8c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "pretrain = True\n",
    "sampler = False\n",
    "dropout = 0.2\n",
    "weight_decay = False\n",
    "weight_entropy = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9439296-9a29-479e-9c48-ee4968bd9987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validasi: 440\n",
      "Training: 1760\n"
     ]
    }
   ],
   "source": [
    "# Test and Training size\n",
    "data_loader = data_load(batch_size,\n",
    "                        train=data['train'],\n",
    "                        val=data['test'],\n",
    "                        transform=transform,\n",
    "                        sampler=sampler)\n",
    "\n",
    "config = config_model_mobile(dropout=dropout, lr=0.001,\n",
    "                      weight_decay=weight_decay,\n",
    "                      kelas=kelas,\n",
    "                      pretrained=pretrain,\n",
    "                      data_loader=data_loader, freeze=False)\n",
    "\n",
    "print('Validasi: ' + str(data_loader['sizes']['val']))\n",
    "print('Training: ' + str(data_loader['sizes']['train']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b76caaf-33c7-4e26-b760-58923445e6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 60\n",
    "to_train = True\n",
    "check = True\n",
    "num_mod = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104586c7-472b-4d57-92ab-9ad391ec889f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 2.22354 Akurasi: 0.34830\n",
      "val Loss: 2.14491 Akurasi: 0.40455\n",
      "Best Val Test Acc âœ”\n",
      "\n",
      "Epoch 1/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 1.42219 Akurasi: 0.55852\n",
      "val Loss: 1.92671 Akurasi: 0.48864\n",
      "Best Val Test Acc âœ”\n",
      "\n",
      "Epoch 2/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.91539 Akurasi: 0.71932\n",
      "val Loss: 1.64882 Akurasi: 0.53409\n",
      "Best Val Test Acc âœ”\n",
      "\n",
      "Epoch 3/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.54935 Akurasi: 0.83409\n",
      "val Loss: 2.00955 Akurasi: 0.52273\n",
      "\n",
      "Epoch 4/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.37528 Akurasi: 0.89034\n",
      "val Loss: 1.88997 Akurasi: 0.53636\n",
      "Best Val Test Acc âœ”\n",
      "\n",
      "Epoch 5/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.30047 Akurasi: 0.91818\n",
      "val Loss: 1.92022 Akurasi: 0.53182\n",
      "\n",
      "Epoch 6/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.28215 Akurasi: 0.91989\n",
      "val Loss: 2.01058 Akurasi: 0.55909\n",
      "Best Val Test Acc âœ”\n",
      "\n",
      "Epoch 7/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.25374 Akurasi: 0.92102\n",
      "val Loss: 2.07744 Akurasi: 0.56818\n",
      "Best Val Test Acc âœ”\n",
      "\n",
      "Epoch 8/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.25520 Akurasi: 0.92159\n",
      "val Loss: 2.28597 Akurasi: 0.52500\n",
      "\n",
      "Epoch 9/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.23740 Akurasi: 0.93125\n",
      "val Loss: 2.28855 Akurasi: 0.51818\n",
      "\n",
      "Epoch 10/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.23987 Akurasi: 0.93295\n",
      "val Loss: 2.23573 Akurasi: 0.53636\n",
      "\n",
      "Epoch 11/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.19885 Akurasi: 0.94205\n",
      "val Loss: 2.40343 Akurasi: 0.53864\n",
      "\n",
      "Epoch 12/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.16763 Akurasi: 0.95057\n",
      "val Loss: 2.29296 Akurasi: 0.56136\n",
      "\n",
      "Epoch 13/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.14186 Akurasi: 0.95568\n",
      "val Loss: 2.17427 Akurasi: 0.53636\n",
      "\n",
      "Epoch 14/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.14363 Akurasi: 0.95341\n",
      "val Loss: 2.22154 Akurasi: 0.55455\n",
      "\n",
      "Epoch 15/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.12097 Akurasi: 0.96250\n",
      "val Loss: 2.23848 Akurasi: 0.57273\n",
      "Best Val Test Acc âœ”\n",
      "\n",
      "Epoch 16/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.12550 Akurasi: 0.96761\n",
      "val Loss: 2.37561 Akurasi: 0.55682\n",
      "\n",
      "Epoch 17/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.10214 Akurasi: 0.96420\n",
      "val Loss: 2.47599 Akurasi: 0.54318\n",
      "\n",
      "Epoch 18/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.14296 Akurasi: 0.95511\n",
      "val Loss: 2.41105 Akurasi: 0.57273\n",
      "\n",
      "Epoch 19/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.13814 Akurasi: 0.95341\n",
      "val Loss: 2.32048 Akurasi: 0.52727\n",
      "\n",
      "Epoch 20/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.15001 Akurasi: 0.94602\n",
      "val Loss: 2.71253 Akurasi: 0.54545\n",
      "\n",
      "Epoch 21/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.14889 Akurasi: 0.94432\n",
      "val Loss: 2.61214 Akurasi: 0.55455\n",
      "\n",
      "Epoch 22/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.15013 Akurasi: 0.95341\n",
      "val Loss: 2.42490 Akurasi: 0.55227\n",
      "\n",
      "Epoch 23/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.16237 Akurasi: 0.94830\n",
      "val Loss: 2.53171 Akurasi: 0.55909\n",
      "\n",
      "Epoch 24/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.16034 Akurasi: 0.95057\n",
      "val Loss: 2.38287 Akurasi: 0.55000\n",
      "\n",
      "Epoch 25/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.15762 Akurasi: 0.94602\n",
      "val Loss: 2.44345 Akurasi: 0.52955\n",
      "\n",
      "Epoch 26/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.19181 Akurasi: 0.93977\n",
      "val Loss: 2.71763 Akurasi: 0.51364\n",
      "\n",
      "Epoch 27/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.15026 Akurasi: 0.95114\n",
      "val Loss: 2.41423 Akurasi: 0.55227\n",
      "\n",
      "Epoch 28/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.12254 Akurasi: 0.95511\n",
      "val Loss: 2.39718 Akurasi: 0.53409\n",
      "\n",
      "Epoch 29/59\n",
      "Lr: 0.001\n",
      "==========\n",
      "train Loss: 0.11598 Akurasi: 0.95625\n",
      "val Loss: 2.64063 Akurasi: 0.52500\n",
      "\n",
      "Epoch 30/59\n",
      "Lr: 0.0001\n",
      "==========\n",
      "train Loss: 0.07015 Akurasi: 0.97500\n",
      "val Loss: 2.33498 Akurasi: 0.56818\n",
      "\n",
      "Epoch 31/59\n",
      "Lr: 0.0001\n",
      "==========\n",
      "train Loss: 0.04565 Akurasi: 0.98125\n",
      "val Loss: 2.26361 Akurasi: 0.57500\n",
      "Best Val Test Acc âœ”\n",
      "\n",
      "Epoch 32/59\n",
      "Lr: 0.0001\n",
      "==========\n",
      "train Loss: 0.03493 Akurasi: 0.98580\n",
      "val Loss: 2.22348 Akurasi: 0.58864\n",
      "Best Val Test Acc âœ”\n",
      "\n",
      "Epoch 33/59\n",
      "Lr: 0.0001\n",
      "==========\n",
      "train Loss: 0.03223 Akurasi: 0.98580\n",
      "val Loss: 2.21643 Akurasi: 0.59091\n",
      "Best Val Test Acc âœ”\n",
      "\n",
      "Epoch 34/59\n",
      "Lr: 0.0001\n",
      "==========\n",
      "train Loss: 0.03234 Akurasi: 0.98295\n",
      "val Loss: 2.21209 Akurasi: 0.59318\n",
      "Best Val Test Acc âœ”\n",
      "\n",
      "Epoch 35/59\n",
      "Lr: 0.0001\n",
      "==========\n",
      "train Loss: 0.03199 Akurasi: 0.98352\n",
      "val Loss: 2.21037 Akurasi: 0.59545\n",
      "Best Val Test Acc âœ”\n",
      "\n",
      "Epoch 36/59\n",
      "Lr: 0.0001\n",
      "==========\n",
      "train Loss: 0.03021 Akurasi: 0.98409\n",
      "val Loss: 2.21220 Akurasi: 0.59545\n",
      "\n",
      "Epoch 37/59\n",
      "Lr: 0.0001\n",
      "==========\n",
      "train Loss: 0.02970 Akurasi: 0.98466\n",
      "val Loss: 2.20660 Akurasi: 0.60227\n",
      "Best Val Test Acc âœ”\n",
      "\n",
      "Epoch 38/59\n",
      "Lr: 0.0001\n",
      "==========\n",
      "train Loss: 0.03008 Akurasi: 0.98068\n",
      "val Loss: 2.19298 Akurasi: 0.60000\n",
      "\n",
      "Epoch 39/59\n",
      "Lr: 0.0001\n",
      "==========\n",
      "train Loss: 0.02811 Akurasi: 0.98523\n",
      "val Loss: 2.18491 Akurasi: 0.59545\n",
      "\n",
      "Epoch 40/59\n",
      "Lr: 0.0001\n",
      "==========\n",
      "train Loss: 0.02677 Akurasi: 0.98580\n",
      "val Loss: 2.18109 Akurasi: 0.59091\n",
      "\n",
      "Epoch 41/59\n",
      "Lr: 0.0001\n",
      "==========\n",
      "train Loss: 0.02773 Akurasi: 0.98409\n",
      "val Loss: 2.17056 Akurasi: 0.60000\n",
      "\n",
      "Epoch 42/59\n",
      "Lr: 0.0001\n",
      "==========\n",
      "train Loss: 0.02757 Akurasi: 0.98466\n",
      "val Loss: 2.19877 Akurasi: 0.60227\n",
      "\n",
      "Epoch 43/59\n",
      "Lr: 0.0001\n",
      "==========\n",
      "train Loss: 0.02748 Akurasi: 0.98523\n",
      "val Loss: 2.19358 Akurasi: 0.60000\n",
      "\n",
      "Epoch 44/59\n",
      "Lr: 0.0001\n",
      "==========\n",
      "train Loss: 0.02642 Akurasi: 0.98636\n",
      "val Loss: 2.20337 Akurasi: 0.60000\n",
      "\n",
      "Epoch 45/59\n",
      "Lr: 0.0001\n",
      "==========\n",
      "train Loss: 0.02728 Akurasi: 0.98580\n",
      "val Loss: 2.21721 Akurasi: 0.60227\n",
      "\n",
      "Epoch 46/59\n",
      "Lr: 0.0001\n",
      "==========\n",
      "train Loss: 0.02621 Akurasi: 0.98693\n",
      "val Loss: 2.18897 Akurasi: 0.60455\n",
      "Best Val Test Acc âœ”\n",
      "\n",
      "Epoch 47/59\n",
      "Lr: 0.0001\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "if to_train:\n",
    "    coba_train(config, transform,\n",
    "               data_loader, epoch=epoch,\n",
    "               pretrained=pretrain,\n",
    "               sampler=sampler,\n",
    "               dropout=dropout,\n",
    "               batch_sizes=batch_size,\n",
    "               sliced=data,\n",
    "               weight_entropy=weight_entropy,\n",
    "               weight_decay=weight_decay, \n",
    "               path_save=path_save,\n",
    "               join=join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "08e8ec88-211d-4e1c-ad3b-8bfe912fefa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hana\\AppData\\Local\\Temp\\ipykernel_16804\\986743857.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(path_mod)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 60 \n",
      "Acc: 0.6159090995788574 \n",
      "loss: 2.0883054733276367 \n",
      "transform: {'train': Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      "), 'val': Compose(\n",
      "    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=True)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")} \n",
      "batch sizes: 100 \n",
      "pretrain: True \n",
      "using sampler: False \n",
      "dropout: 0.2 \n",
      "weight_decay: False \n",
      " Data: {'train': 'clean/fold 2/original/train', 'test': 'clean/fold 2/original/test'}\n"
     ]
    }
   ],
   "source": [
    "#check model\n",
    "if check:\n",
    "    check_model(path_mod,num_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7ade6dee-72f2-4e73-94bd-bfe34623af4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folder(used_data, folder_dst, kelas, jumlah_fold):\n",
    "    for split in ['train', 'test']:\n",
    "        for cls in kelas:\n",
    "            os.makedirs(os.path.join(used_data, f'fold {jumlah_fold + 1}', folder_dst, split, cls), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc5c1f9-68fd-41f4-a0d4-cb54566a0d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
